---
title: Parametric Tests
draft: false
summary: test
---

import TOCInline from 'pliny/ui/TOCInline';

<TOCInline toc={props.toc} asDisclosure />

## Parametric Tests

Parametric tests for nonlinearity are based on specific nonlinear models. They are more powerful than nonparametric tests if the underlying nonlinear model is correctly specified. However, they may have little power in detecting other types of nonlinearity. We discuss several commonly used parametric tests in this section.

### RESET Test

The regression error specification test (RESET) of Ramsey (1969) is a general test for misspecification of functional form. The idea is to use powers of the fitted values from a linear model as additional regressors to see if they have any significance. For a univariate time series $\{r_t\}$, the test proceeds as follows:

1. Fit a linear AR(p) model to $r_t$:

$$r_t = \phi_0 + \phi_1 r_{t-1} + \cdots + \phi_p r_{t-p} + e_t$$

and obtain the fitted values $\hat{r}_t$.

2. Estimate the augmented regression:

$$r_t = \phi_0 + \phi_1 r_{t-1} + \cdots + \phi_p r_{t-p} + \beta_1 \hat{r}_t^2 + \beta_2 \hat{r}_t^3 + \cdots + \beta_m \hat{r}_t^{m+1} + u_t$$

3. Test the null hypothesis $H_0: \beta_1 = \beta_2 = \cdots = \beta_m = 0$ using an F-test or likelihood ratio test.

If the null hypothesis is rejected, it suggests that the linear AR(p) model is misspecified and some form of nonlinearity may be present.

### Threshold Autoregressive (TAR) Test

Tsay (1989) proposed a test for threshold nonlinearity based on arranged autoregression. The test proceeds as follows:

1. Fit an AR(p) model to $\{r_t\}$ and obtain the residuals $\hat{e}_t$.

2. Choose a threshold variable $z_t$ (e.g., $z_t = r_{t-d}$ for some delay d).

3. Sort the data according to $z_t$ in ascending order.

4. Perform the following regression using the sorted data:

$$\hat{e}_t = \beta_0 + \beta_1 r_{t-1} + \cdots + \beta_p r_{t-p} + u_t$$

5. Compute the predictive residuals $\hat{u}_t$ recursively.

6. Calculate the test statistic:

$$F = \frac{(SSR_0 - SSR_1) / p}{SSR_1 / (T - 2p - 1)}$$

where $SSR_0 = \sum_{t=p+1}^T \hat{e}_t^2$, $SSR_1 = \sum_{t=p+1}^T \hat{u}_t^2$, and T is the sample size.

Under the null hypothesis of linearity, the F-statistic follows an F-distribution with p and T-2p-1 degrees of freedom.

### Smooth Transition Autoregressive (STAR) Test

Ter√§svirta (1994) proposed a test for smooth transition nonlinearity based on a Taylor series approximation of the STAR model. The test procedure is as follows:

1. Fit an AR(p) model to $\{r_t\}$.

2. Regress the residuals $\hat{e}_t$ on $r_{t-1}, \ldots, r_{t-p}$ and $r_{t-d}, r_{t-d}^2, r_{t-d}^3$ for some delay d:

$$\hat{e}_t = \beta_0 + \beta_1 r_{t-1} + \cdots + \beta_p r_{t-p} + \beta_{p+1} r_{t-d} + \beta_{p+2} r_{t-d}^2 + \beta_{p+3} r_{t-d}^3 + u_t$$

3. Test the null hypothesis $H_0: \beta_{p+1} = \beta_{p+2} = \beta_{p+3} = 0$ using an F-test.

If the null hypothesis is rejected, it suggests the presence of smooth transition nonlinearity.

### Bilinear Test

Maravall (1983) proposed a test for bilinear nonlinearity based on the following augmented regression:

$$r_t = \phi_0 + \phi_1 r_{t-1} + \cdots + \phi_p r_{t-p} + \beta_1 r_{t-i} \hat{e}_{t-j} + \beta_2 r_{t-k} \hat{e}_{t-l} + u_t$$

where $\hat{e}_t$ are the residuals from an AR(p) fit. The null hypothesis of linearity is $H_0: \beta_1 = \beta_2 = 0$, which can be tested using an F-test or likelihood ratio test.

### ARCH-LM Test

Engle (1982) proposed the Lagrange Multiplier (LM) test for autoregressive conditional heteroskedasticity (ARCH) effects. The test procedure is as follows:

1. Fit an AR(p) model to $\{r_t\}$ and obtain the residuals $\hat{e}_t$.

2. Regress $\hat{e}_t^2$ on a constant and $\hat{e}_{t-1}^2, \ldots, \hat{e}_{t-q}^2$:

$$\hat{e}_t^2 = \alpha_0 + \alpha_1 \hat{e}_{t-1}^2 + \cdots + \alpha_q \hat{e}_{t-q}^2 + u_t$$

3. Calculate the test statistic $LM = TR^2$, where T is the sample size and $R^2$ is the coefficient of determination from the regression in step 2.

Under the null hypothesis of no ARCH effects, LM follows asymptotically a chi-square distribution with q degrees of freedom.

### BDS Test

Brock, Dechert, and Scheinkman (1987) proposed a test for nonlinear serial dependence based on the correlation integral. The test statistic is:

$$W_{m,T}(\epsilon) = \sqrt{T} \frac{C_{m,T}(\epsilon) - C_{1,T}(\epsilon)^m}{\sigma_{m,T}(\epsilon)}$$

where:

- $C_{m,T}(\epsilon)$ is the correlation integral for embedding dimension m
- $T$ is the sample size
- $\epsilon$ is the proximity parameter
- $\sigma_{m,T}(\epsilon)$ is the standard deviation of $C_{m,T}(\epsilon) - C_{1,T}(\epsilon)^m$

Under the null hypothesis of independent and identical distribution (i.i.d.), $W_{m,T}(\epsilon)$ follows asymptotically a standard normal distribution.

The BDS test can detect various types of nonlinearity and non-random chaotic dynamics. It is typically applied to the residuals of a linear model to test for remaining nonlinear structure.

### Neural Network Test

Lee, White, and Granger (1993) proposed a test for neglected nonlinearity based on neural network models. The test procedure is as follows:

1. Fit a linear AR(p) model to $\{r_t\}$ and obtain the residuals $\hat{e}_t$.

2. Generate q random vectors $\mathbf{v}_j$ of length p+1, where the elements are drawn from a uniform distribution on [-1, 1].

3. Construct q "hidden units" $h_j(\mathbf{x}_t) = \psi(\mathbf{v}_j' \mathbf{x}_t)$, where $\mathbf{x}_t = (1, r_{t-1}, \ldots, r_{t-p})'$ and $\psi$ is the logistic function.

4. Regress $\hat{e}_t$ on $h_1(\mathbf{x}_t), \ldots, h_q(\mathbf{x}_t)$:

$$\hat{e}_t = \beta_0 + \beta_1 h_1(\mathbf{x}_t) + \cdots + \beta_q h_q(\mathbf{x}_t) + u_t$$

5. Test the null hypothesis $H_0: \beta_1 = \cdots = \beta_q = 0$ using an F-test or likelihood ratio test.

If the null hypothesis is rejected, it suggests the presence of neglected nonlinearity that can be captured by a neural network model.

These parametric tests provide a range of tools for detecting specific types of nonlinearity in time series data. However, it's important to note that each test has its strengths and weaknesses, and no single test can detect all forms of nonlinearity. In practice, it's often advisable to use a combination of tests to gain a comprehensive understanding of the nonlinear structure in the data.

When applying these tests, researchers should also be aware of potential issues such as:

1. Size distortions in small samples
2. Sensitivity to the choice of parameters (e.g., embedding dimension in the BDS test)
3. Power against specific alternatives
4. Robustness to outliers and structural breaks

Therefore, careful interpretation of test results and consideration of the specific characteristics of the time series under study are crucial for drawing valid conclusions about nonlinearity.
